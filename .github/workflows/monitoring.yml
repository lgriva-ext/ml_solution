name: Monitoring Workflow


on:
  workflow_dispatch:

  #schedule:
    #- cron: "0 8 * * *"


jobs:
#  monitor_metrics:
#    runs-on: ubuntu-latest
#    environment:
#      name: staging
#    env:
#    # DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_STAGING_TOKEN }}
#      DATABRICKS_CLUSTER_ID: ${{ secrets.DATABRICKS_CLUSTER_ID }}
#      DATABRICKS_HOST: ${{ secrets.DATABRICKS_WORKSPACE }}

#    steps:
#    - name: Checkout repository
#      uses: actions/checkout@v3
#      with:
#        fetch-depth: 0

#    - name: setup python
#      uses: actions/setup-python@v3
#      with:
#        python-version: "3.8"

#    - name: pip install
#      run: |
#        python -m pip install --upgrade pip setuptools wheel

#    - name: install-databricks-cli
#      uses: microsoft/install-databricks-cli@v1.0.0

#    # Connect to azure
#    - uses: Azure/login@v1
#      name: Login to Azure
#      with:
#        creds: '{"clientId":"${{ secrets.CLIENT_ID }}","clientSecret":"${{ secrets.CLIENT_SECRET }}","subscriptionId":"${{ secrets.SUBSCRIPTION_ID }}","tenantId":"${{ secrets.TENANT_ID }}"}'

#    # Set databricks token as environmental variable
#    - name: Generate databricks token
#      id: generate-token
#      run: |
#        echo "DATABRICKS_TOKEN=$(az account get-access-token \
#          --resource 2ff814a6-3304-4ab8-85cb-cd0e6f879c1d | jq .accessToken -r)" >> $GITHUB_ENV

#    - name: run monitoring job
#      id: run_monitoring_job
#      run: |
#        databricks jobs run-now --job-id ${{ secrets.MONITORING_JOB_ID }}
#        echo "$(python $GITHUB_WORKSPACE/jobs/job_waiter.py ${{ secrets.MONITORING_JOB_ID }})" >> GITHUB_OUTPUT

#    - name: run training pipeline
#      if: ${{ steps.run_monitoring_job.outputs.state == 'FAILED' }}
#      run: databricks jobs run-now --job-id ${{ secrets.JOB_ID_ACTIVE_PROD_JOB }}

  monitor_data:
    runs-on: ubuntu-latest
    environment:
      name: staging
    env:
    # DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_STAGING_TOKEN }}
      DATABRICKS_CLUSTER_ID: ${{ secrets.DATABRICKS_CLUSTER_ID }}
      DATABRICKS_HOST: ${{ secrets.DATABRICKS_WORKSPACE }}

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
      with:
        fetch-depth: 0

    - name: setup python
      uses: actions/setup-python@v3
      with:
        python-version: "3.8"

    - name: pip install
      run: |
        python -m pip install --upgrade pip setuptools wheel

    - name: install-databricks-cli
      uses: microsoft/install-databricks-cli@v1.0.0

    # Connect to azure
    - uses: Azure/login@v1
      name: Login to Azure
      with:
        creds: '{"clientId":"${{ secrets.CLIENT_ID }}","clientSecret":"${{ secrets.CLIENT_SECRET }}","subscriptionId":"${{ secrets.SUBSCRIPTION_ID }}","tenantId":"${{ secrets.TENANT_ID }}"}'

    # Set databricks token as environmental variable
    - name: Generate databricks token
      id: generate-token
      run: |
        echo "DATABRICKS_TOKEN=$(az account get-access-token \
          --resource 2ff814a6-3304-4ab8-85cb-cd0e6f879c1d | jq .accessToken -r)" >> $GITHUB_ENV

    # Set git_sha as environmental variable in production job
    - name: Set cut date
      run: echo "train_date=${{ secrets.CUT_DATE }}" >> $GITHUB_ENV

    # Update cluster conf
    - name: Update cluster conf
      run: |
        json=$(cat $GITHUB_WORKSPACE/jobs/cluster_conf.json)
        json=$(echo $json | jq -r ".spark_env_vars.train_date = \"${{ env.train_date }}\"")
        json=$(echo $json | jq -r ".cluster_id = \"${{ secrets.DATABRICKS_PROD_CLUSTER_ID }}\"")
        databricks clusters edit --json "$json"

    - name: run monitoring job
      id: run_monitoring_job
      run: |
        databricks jobs run-now --job-id ${{ secrets.MONITORING_DATA_JOB_ID }}
        echo "$(python $GITHUB_WORKSPACE/jobs/job_waiter.py ${{ secrets.MONITORING_DATA_JOB_ID }})" >> GITHUB_OUTPUT

    - name: run training pipeline
      if: ${{ steps.run_monitoring_job.outputs.state == 'FAILED' }}
      run: databricks jobs run-now --job-id ${{ secrets.JOB_ID_ACTIVE_PROD_JOB }}
